<app-data-mining-navigation></app-data-mining-navigation>
<div class="container-sm">
    <h1 style="text-align: center;">Models</h1>
    <p>
        In order to model the data, we took a few different approaches and utilized a combination of unsupervised and supervised methods.

    <h2>Unsupervised Methods</h2>
    For the unsupervised methods, we utilized association rule mining (ARM) and k-means clustering.

    <h3>Association Rule Mining</h3>
    <p>
        We applied association rule mining to the reviews of the games. We looked at Steam Apps that were classified as a "game" (in other words, we didn't look at DLC or other non-game Steam Apps), and we looked at differences among the top 10 genres. We filtered game reviews by the ratio of positive reviews to negative reviews of a game. If a game had more positive reviews than negative, it was considered a positive and vice versa. We acknowledge that this is not the best method, especially considering Steam reviews are tagged as either positive or negative. A bug in code caused that review tag to not be collected. Grouping reviews by how positively overall the game they are associated with is the best approximation.

    <p>
        ARM requires transaction data. To create the transaction data, we first extracted the necessary reviews according to liked and disliked games and genre. We removed any line break characters, removed capital letters, punctuation, numbers, non-latin characters, duplicate words, and a set of words (such as "game", "ever", "it", "etc") that provide no meaning. Afterwards, we saved the cleaned words as basket data. The two images below show messy data (top) and clean data (right).

    <div class="row">
        <div class="col-sm-12">
            <img class="img-center col-sm-12" src="../../../assets/data-mining-assets/visualisations/arm/raw-arm-text.png" alt="">
        </div>
        <div class="col-sm-12">
            <img class="img-center" src="../../../assets/data-mining-assets/visualisations/arm/transaction-data-for-arm.png" alt="">
        </div>
    </div>

    <p>
        Using thresholds of 0.01 and 0.4 for support and confidence, respectively, we generated the following plots that describe the found association rules.

        <div class="row">
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/liked-action.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/liked-adventure.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/liked-casual.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/liked-indie.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/liked-multiplayer.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/liked-racing.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/liked-rpg.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/liked-simulation.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/liked-sports.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/liked-strategy.png">
        </div>

    <p>
        From this, we draw two separate interpretations:
        <ol>
            <li>A quality game allows the player on the story and the overall message of a game. Art, music, and game mechanics all seamlessly work together to create an experience rather than any one of those removing the player from the flow of the game.</li>
            <li>Story is a potential driving factor in a quality game. Without a good story, the game will suffer.</li>
        </ol>

    <p>
        Assocation plots for reviews for mostly negative games were also created using support and confidence thresholds of 0.02 and 0.55, respectively.

        <div class="row">
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/disliked-action.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/disliked-adventure.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/disliked-casual.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/disliked-indie.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/disliked-multiplayer.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/disliked-racing.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/disliked-rpg.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/disliked-simulation.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/disliked-sports.png">
            </div>
            <div class="col-sm-6">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/arm/disliked-strategy.png">
        </div>

    <p>
        Negative review are much more scattered about. While RPGs center around story (which in this case might indicate a bad story) to a degree, the other plots are less centralized around a common theme which could indicate that some elements of a game could be good, but one bad element of a game can ruin the whole thing. 

    <h3>K-Means Clustering Analysis</h3>
    We also performed K-Means clustering. We grouped Steam products based on total reviews, price, and publisher. The steps include:

    <ol>
        <li>
            Data Preprocessing: Converts publisher into numerical columns using One-Hot Encoding. Scales numerical features (Total_Reviews and Price) to have a mean of 0 and a standard deviation of 1.
        </li>
        <li>
            Clustering: With an optimal k=3, clusters group products into categories like high review/high price(premium), moderate review/mid-range price (popular mid-tier), and low review/low price (budget).
        </li>
        <li>
            Visualizations: A scatterplot visualizes clusters by total reviews and price, with each cluster color-coded.
        </li>
        <li>
            Key Insights: Products are segmented into distinct price and popularity tiers, aiding in market understanding.
        </li>
    </ol>

    <div class="row">
        <div class="col-sm-12">
            <img class="img-center" src="../../../assets/data-mining-assets/visualisations/other/k-means-clustering.png">
        </div>
        <div class="col-sm-12">
            <img class="img-center" src="../../../assets/data-mining-assets/visualisations/other/bar-plot.png">
        </div>
        <div class="col-sm-12">
            <img class="img-center" src="../../../assets/data-mining-assets/visualisations/other/box-plot.png">
        </div>
    </div>

    <h2>Supervised Learning</h2>
    <h3>CLIP</h3>
    <h4>Model Explanation</h4>
    <p>
        CLIP is a multimodal model, proposed by OpenAI, that aligns textual and image embeddings into a joint space. It was trained to predict which caption fits best for an image among candidates, allowing it to learn associations of visual and textual data. Trained on diverse image-text pairs, CLIP can execute tasks such as image classification, retrieval, and zero-shot learning without fine-tuning specifically for individual tasks. Using a dual encoder architecture, it processes images through a vision model-e.g., ResNet or ViT-and processes text using a transformer to produce embeddings to be compared. Such flexibility and generalization make CLIP a very powerful model for different visual-linguistic applications.

    <h4>Why We Used It</h4>
    <p>
        We utilized the CLIP model in our project to examine and find associations between game images and their textual descriptions. The ability of this model to create a common embedding space for text and images allowed us to efficiently perform tasks like image classification and retrieval, helping uncover patterns, understand context, and improve insight into the relationships between visuals and game descriptions.

    <h4>Data Cleaning</h4>
    <p>
        The images below show data before (top) and after (bottom) cleaning.

    <div class="row">
        <div class="col-sm-6">
            <img class="img-center" src="../../../assets/data-mining-assets/visualisations/clip/clip-messy-data.png" alt=""><br>
        </div>
        <div class="col-sm-6">
            <img class="img-center" src="../../../assets/data-mining-assets/visualisations/clip/clip-clean-data.png" alt=""><br>
        </div>
    </div>

    <p>
        This would serve to clean game descriptions of noise like irrelevant words and characters, hence making the text data concise and meaningful. The preprocessing step helps in improving the quality of the textual embeddings that are generated by the CLIP model, therefore improving its ability to relate game descriptions with their corresponding images accurately. Cleaned data reduces computational complexity and improves overall model performance.
    <p>
        Cleaning was also done for image dataset, such as removing 404 error URLs and only filtering screenshots for more consistent training.

    <h4>Model Evaluation (Using Similarity Scores)</h4>
    <div class="row">
        <div class="col-sm-12">
            <img class="img-center-m" src="../../../assets/data-mining-assets/visualisations/clip/clip-similarity.png" alt=""><br>
        </div>
    </div>
    <p>
        The similarity scores indicate how well text embeddings (e.g., game descriptions) align with image embeddings in the CLIP model. Each value represents the similarity between a text-image pair where higher scores indicate stronger associations. Rows correspond to text embeddings, columns correspond to image embeddings, and together this allows for an evaluation of CLIP's effectiveness at multimodal alignment. The scores are cosine similarity, between 0 and 1. Since we are finding custom descriptions for completely new images, even a score above 0.2 is good.

        <div class="row">
            <div class="col-sm-12">
                <img class="img-center-l" src="../../../assets/data-mining-assets/visualisations/clip/clip-output.png" alt=""><br>
            </div>
        </div>
    <p>
        The CLIP is model is very effective in describing what each game image is. In a matrix of 10 images, it was able to correctly describe each image. Thus proving CLIP is a effective image to text model. The examples of results provided show the capability of the CLIP model in analyzing and describing game screenshots in high detail. For each of the nine game images, CLIP identified relevant tags or genres such as "space combat simulation," "stealth game," "resource management game," and "visual novel," among others. It successfully aligned visual elements from the images with meaningful semantic labels, showcasing its capability to understand and interpret visual data in the gaming context. The CLIP is model is very effective in describing what each game image is. In a matrix of 10 images, it was able to correctly describe each image. Thus proving CLIP is an effective image to text model.

    <h4>What We Learned</h4>
    <p>
        This functionality has many applications in the analysis of games. CLIP enables automation in categorizing and tagging games with screenshots, reducing human effort and improving scalability for large gaming datasets. This can be useful for game developers and platforms in streamlining their metadata creation processes, therefore making it easier for end-users to discover or search for games. It also improves the quality of the recommendation systems by allowing them to suggest games with appealing visuals or gameplay themes that appeal to the users' likings.

    <p>
        Moreover, the ability of CLIP to extract meaningful insights from images will help in content moderation, ensuring the proper classification of the games. By pairing visual data with descriptive text, CLIP bridges the gap between visual representation and semantic understanding and is a powerful tool for indexing, filtering, and analysis of games efficiently and in a scalable manner.
</div>  