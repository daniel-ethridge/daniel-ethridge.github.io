<body class="project-desc">
    
    <div class="row">
        <div class="col-md-4"></div>
        <div class="col-md-4">
            <h2 class="text-center"><i>{{project.name}}</i></h2>
        </div>
        <div class="col-md-4" style="text-align: right;">
            <a routerLink="/portfolio">
                <button class="btn btn-primary">Back to Portfolio</button>
            </a>
        </div>
    </div>

    <p>
        Shape song is a custom app that I developed from scratch to help research cross-instrumental control in a network music environment. I defined cross instrumental control as the ability for someone to control timbral, temporal, melodic, etc. properties of someone else’s instrument or device. Imagine playing music with a group of people, and you and your friend are playing synthesizers. Of course you can both turn the knobs on your own synthesizer, but what if you could also turn the knobs on each other’s synthesizer? Check out the demo video below!
    </p>
    <div class="text-center mb-3">
        <a href={{videoLink}}, target="_blank">
            <img src={{videoImg}} alt="Shape Song">
        </a>
    </div>

    <p>
        Shape song was developed using the Unity video game engine, Audiokinetic's interactive audio engine WWise, and the Photon Engine API for networking. Three people could participate at once, and each was represented by an avatar in the application. Pressing the “J” key on the keyboard, a note would play with pitch determined by the respective avatar's vertical position on the screen and volume determined by horizontal location. A higher position meant a higher pitch, while being further right on the screen meant a louder note.
    </p>
    <p>
        The avatars all had four body parts: a head, a torso, arms, and legs. Changing the color of those would, in effect, “turn the knobs” of that participant's synthesizer and change their sound.
    </p>
    <p>
        All participants could create and delete squares and circles anywhere on the screen. Squares represented percussion instruments, while circles represented melodic lines. The number of each shape that was present, the colors of the shapes, and the brightnesses of the background all allowed participants to create different backing tracks to accompany them while they played their own synth with the “J” key. The frequency cutoff of a global low-pass filter was controlled by an intensity slider which also controlled the brightness of the background. All the background music was synced together for each participant using a master clock inside of WWise.
    </p>
    <p>
        Importantly, each participant was able to create and delete all shapes, modify colors and brightness values for all shapes, and change colors of all avatars. The study was divided into three parts: no cross-instrumental control (only modify your own avatar and one shape or the intensity slider), some cross-instrumental control (modify your avatar and someone elses and control either two shapes or one shape and the intensity slider), or total cross instrumental control (everyone controls everything).
    </p>
    <p>
        Through a focus group at the end, I saw that the second condition (some cross-instrumental control) seemed to foster the most engagement. No cross-instrumental control was too limiting, while total cross-instrumental control was overwhelming. This result could be further tested and used in creating new unique and meaningful interactive performances and installations, both in person and remotely.
    </p>
</body>