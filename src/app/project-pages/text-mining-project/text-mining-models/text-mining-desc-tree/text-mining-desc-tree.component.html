<div class="main-background">
    <div class="container">

            <app-text-mining-navigation/>
            <h1 class="text-center">Decision Trees</h1>
            <p>
                <em>All code can be found <a target="_blank" href="https://github.com/daniel-ethridge/text-mining-project/blob/main/supervised-learning/supervised_learning.ipynb">here</a>, and all data can be found <a target="_blank" href="https://github.com/daniel-ethridge/text-mining-project-data">here</a>.</em>
            </p>
            <h2>Overview</h2>
            <p>
                Look at the image below:
            </p>
            <div class="row">
                <div class="col-md-12 text-center">
                    <img class="img-fluid" src="../../../../assets/ml-assets/ml-supervised/funny-dt.jpg" alt="">
                </div>
            </div>
            
            <p>
                Now look at the next image:
            </p>
            <div class="row">
                <div class="col-md-12 text-center">
                    <img class="img-fluid" src="../../../../assets/ml-assets/ml-supervised/tree0.png" alt="">
                </div>
            </div>
    
            <p>
                Comical decision flow charts like the first image are all over the internet, but they are not actually too far off from a decision tree like the second image used in machine learning to generate predictions. Both images show a starting node, they both branch off to lower nodes, and the further down the tree things progress, the more complicated things seem to get. Machine learning decision trees are just these flowchart-like structures that are created using data. 
    
            <p>
                With decision trees, I will aim to predict whether a news article about a mass shooting was written by a left wing or right wing news outlet. Additionally, given decent prediction accuracy, we can view the actual decision trees to observe which words are at the top level nodes of the trees. 
    
            <h2>Data Preparation</h2>
            <p>
                For supervised learning, labeled data is required because the models need a ground truth to find the patterns in a dataset that lead to any specific label. In this case, the labels are "left" and "right". Mapped to numbers with <code>scikit-learn</code>'s <code>LabelEncoder</code>, the labels are 0 and 1. 
    
            <p>
                The full dataset can be found at the link at the top of the page. Go to the clean folder, and see the file called <code>count-4856.csv</code>. An partial image of the full dataset is below.
    
            <div class="text-center my-4">
                <img src="assets/text-mining/supervised-learning/data.png" alt="Partial view of dataset" class="img-fluid">
            </div>
    
            <p>
                To train a model, the data must be split into training and testing data. This is for model evaluation. The point of these models to be able to predict things about data they have not seen, or in this point to predict the political leaning of an article that it has not seen. If the model is evaluated on the data it was trained on, it's like if a student in school was able to study for a test with the exact test and answers that they would later see. It's cheating. Thus, we need to split data into separate training and testing sets. The images on the left show training data and labels, and the image on the right show testing data and labels. Notice the difference in row counts. The training data is 90% of the entire dataset, while the testing set is only 10%.
    
            <div class="row text-center">
                <div class="col-6 my-4">
                <img src="assets/text-mining/supervised-learning/training-data.png" alt="Training data" class="img-fluid">
                </div>
                <div class="col-6 my-4">
                <img src="assets/text-mining/supervised-learning/testing-data.png" alt="Testing data" class="img-fluid">
                </div>
            </div>
            <div class="row text-center">
                <div class="col-6 my-4">
                <img src="assets/text-mining/supervised-learning/training-labels.png" alt="Training labels" class="img-fluid">
                </div>
                <div class="col-6 my-4">
                <img src="assets/text-mining/supervised-learning/testing-labels.png" alt="Testing labels" class="img-fluid">
                </div>
            </div>
    
            <p>
                Note that this is just an example. To train and evaluate the models, I've implemented a flavor of cross validation called monte-carlo cross validation. This is a method where instead of just training and evaluating a model once, we create a new, random train-test split, train, and evaluate several times. By doing this, we can obtain a distribution of each of the metrics used later (i.e. accuracy, precision, recall, and f1 score) and calculate average scores and the standard deviation. This has the benefit of providing more information than just a single number. 
    
            <h2>Results</h2>
            <p>
                With any machine learning model, overfitting is a concern. For decision trees, the hyperparameter that I wanted to tune was the depth of the tree. 
    
            <p>
                To test for overfitting with any model, we can calculate two separate accuracies: one with the model evaluated on the training data one with the model evaluated on the testing data and one on the training data. The image below shows this.
    
            <div class="text-center my-4">
                <img src="assets/text-mining/supervised-learning/dt-overfitting.png" alt="Training and testing accuracy" class="img-fluid">
            </div>
    
            <p>
                This proved to be an important step because the model starts to perform noticeably better on training data than on testing data starting at a max depth of 9. That is the point where overfitting is becoming an issue. Thus, a max depth of 8 was chosen for all future iterations. 
    
            <p>
                The largest peak seems to be around 1.0, right around the default. In other iterations of this plot not shown, 1.0 was not always the highest, but it is safe in this instance to go with alpha = 1 since the difference in accuracies only spans 1%.
    
            <p>
                The 5 plots below show distributions of five evaluation metrics alongside a confusion matrix for the iteration that provided the average accuracy. 
    
            <div class="row text-center mb-4">
                <div class="col-6">
                <img src="assets/text-mining/supervised-learning/dt-accuracy.png" alt="Accuracy distribution" class="img-fluid">
                </div>
                <div class="col-6">
                <img src="assets/text-mining/supervised-learning/dt-precision.png" alt="Precision distribution" class="img-fluid">
                </div>
            </div>
            <div class="row text-center mb-4">
                <div class="col-6">
                <img src="assets/text-mining/supervised-learning/dt-recall.png" alt="Recall distribution" class="img-fluid">
                </div>
                <div class="col-6">
                <img src="assets/text-mining/supervised-learning/dt-f1.png" alt="F1 distribution" class="img-fluid">
                </div>
            </div>
            <div class="row text-center">
                <div class="col-12">
                <img src="assets/text-mining/supervised-learning/dt-conf-mat.png" alt="Confusion matrix" class="img-fluid">
                </div>
            </div>
    
            <h3 id="the-trees">The Trees</h3>
            <p>
                Three decision trees were created. The first was created based on the full data set and is shown below. 
    
            <div class="row text-center my-4">
                <div class="col-12">
                    <img src="assets/text-mining/supervised-learning/dt1.jpg" alt="Full decision tree" class="img-fluid">
                </div>
            </div>
    
            <p>
                The top level root node, the word "matters", is the most significant word according to the tree, so let's remove it and generate a new tree. We obtain the following: 
    
            <div class="row text-center my-4">
                <div class="col-12">
                    <img src="assets/text-mining/supervised-learning/dt2.jpg" alt="Second decision tree" class="img-fluid">
                </div>
            </div>
    
            <p>
                Now the word letter (which was in the second layer of the first tree) is the root node. Let's do this one more time. Removing "letter" from the dataset and creating one more tree gives the following: 
    
            <div class="row text-center my-4">
                <div class="col-12">
                    <img src="assets/text-mining/supervised-learning/dt3.jpg" alt="Third decision tree" class="img-fluid">
                </div>
            </div>
    
            <p>
                Again, a word from the second layer of the prior decision tree, "fight", is shown as the root node. 
    
            <h3 class="mt-5">Comparison with other Models</h3>
            <p>
                The table below shows the decision tree's evaluation metrics compared to a <a href="/portfolio/text-mining/naive-bayes">Naive Bayes Model</a> and three <a href="/portfolio/text-mining/support-vector-machine">Support Vector Machine models</a>. See the pages linked to learn about those!
    
            <div class="text-center my-4">
                <img src="assets/text-mining/supervised-learning/all-results.png" alt="Model comparison" class="img-fluid">
            </div>
    
            <p>
                Decision Tree performs very well compared to the other models, but it's not the best.
    
            <h2>Conclusions</h2>
            <p>
                With A decision tree, we can predict the political affiliation of 4 out of 5 articles correctly. It performs fairly well on with precision, recall, and f1 as well. 
    
            <p>
                Given the decent predictions, the actual trees can tell us more. It is difficult to predict what letter or matters might refer to, but the word "fight" is interesting. Based on the 2nd layer in the tree, we see that if "fight" is in the article, it's more likely to come from the left wing media. This ties in nicely to other various conclusions that show that the left wing media discusses other socioeconomic issues alongside the shootings coverage. As a final comment, these three nodes interestingly match with the <a href="/portfolio/text-mining/support-vector-machine#conclusion">three most important words from the SVM</a>. This would warrant further investigation via unsupervised methods to see what clusters, topics, and associations might revolve around these words.
    </div>
</div>